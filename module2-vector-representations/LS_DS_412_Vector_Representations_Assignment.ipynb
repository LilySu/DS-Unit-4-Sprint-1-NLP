{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_indeed_data(search, num_pages = 1):\n",
    "    \n",
    "#     def scrape_data(tag = None, class_name = None, soup= None):\n",
    "#         data = []\n",
    "        \n",
    "#         if class_name is None:\n",
    "#             tag_list = soup.find_all(tag)\n",
    "#             for num in range(len(tag_list)):\n",
    "#                 data.append(tag_list[num].get_text())\n",
    "#             return data\n",
    "        \n",
    "#         elif tag is None:\n",
    "#             tag_list = soup.find_all(class_ = class_name)\n",
    "#             for num in range(len(tag_list)):\n",
    "#                 data.append(tag_list[num].get_text())\n",
    "#             return data\n",
    "        \n",
    "#         else:\n",
    "#             tag_list = soup.find_all(tag, class_=class_name)\n",
    "#             for num in range(len(tag_list)):\n",
    "#                 data.append(tag_list[num].get_text())\n",
    "#             return data\n",
    "    \n",
    "#     urls = [\"https://www.indeed.com/jobs?q=\"+str(search)+ \"&start=\" + str(num * 10) for num in range(num_pages)]\n",
    "#     df = pd.DataFrame(columns= ['title', 'location', 'summary'])\n",
    "    \n",
    "#     for url in urls:\n",
    "#         request = requests.get(url)\n",
    "#         soup = BeautifulSoup(request.text, 'html.parser')\n",
    "#         #grabbing titles, locations, and summaries\n",
    "#         titles = scrape_data(class_name = 'title', soup= soup)\n",
    "#         locations = scrape_data(class_name= 'location', soup= soup)\n",
    "#         summaries = scrape_data(class_name = 'summary', soup= soup)\n",
    "#         #little bit of data cleaning\n",
    "#         titles = [title.strip('\\n').strip() for title in titles]\n",
    "#         summaries = [summary.strip('\\n').strip() for summary in summaries]\n",
    "#         #concat new data to end of existing dataframe\n",
    "#         columns = ['title', 'location', 'summary']\n",
    "#         data = [[titles[num], locations[num], summaries[num]] for num in range(len(titles))]\n",
    "#         df = pd.concat([df, pd.DataFrame(data= data, columns=columns)], ignore_index= True)\n",
    "    \n",
    "#     return df\n",
    "# # This function will allow you to quickly create a data frame with indeed jobs. \n",
    "# # You just put a search in like \"data scientist\" and the number of pages you want to scrape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlencode\n",
    "from requests_html import HTMLSession\n",
    "from multiprocessing.dummy import Pool\n",
    "from itertools import chain\n",
    "\n",
    "class IndeedJobListings:\n",
    "    '''\n",
    "    Multi-theaded Indeed Job Listings Crawler\n",
    "    Usage:\n",
    "    descriptions = IndeedJobListings('Data Scientist', 'Seattle, WA').get_descriptions()\n",
    "    '''\n",
    "    def __init__(self, search_keyword, location, threads=12):\n",
    "        self.threads = threads\n",
    "        self.base_url = 'https://www.indeed.com'\n",
    "        self.query_url = f'{self.base_url}/jobs?' +\\\n",
    "        urlencode({'q': search_keyword, 'l': location})\n",
    "        self.session = HTMLSession()\n",
    "    \n",
    "    def _get_posting_urls(self, url):\n",
    "        doc = self.session.get(url)\n",
    "        posting_urls = [f'{self.base_url}{e.attrs[\"href\"]}' for e in doc.html.find('.jobtitle.turnstileLink')]\n",
    "        return posting_urls\n",
    "\n",
    "    def _get_description_text(self, url):\n",
    "        doc = self.session.get(url)\n",
    "        description_text = doc.html.find('#jobDescriptionText')[0].text\n",
    "        return description_text\n",
    "                        \n",
    "    def get_descriptions(self, pages=1):\n",
    "        list_urls = [self.query_url] + [f'{self.query_url}&start={x*10}'\n",
    "                                        for x in range(1, pages)]\n",
    "        p = Pool(self.threads)\n",
    "        post_urls = chain(*p.map(self._get_posting_urls, list_urls))\n",
    "        descriptions = p.map(self._get_description_text, post_urls)\n",
    "        return descriptions\n",
    "\n",
    "\n",
    "listings = IndeedJobListings('Data Scientist', 'New York, NY')\n",
    "data = listings.get_descriptions(pages=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "826"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>03</th>\n",
       "      <th>04</th>\n",
       "      <th>07</th>\n",
       "      <th>09</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>100m</th>\n",
       "      <th>...</th>\n",
       "      <th>yes</th>\n",
       "      <th>york</th>\n",
       "      <th>yorkers</th>\n",
       "      <th>youtube</th>\n",
       "      <th>zendesk</th>\n",
       "      <th>zoomrx</th>\n",
       "      <th>zr</th>\n",
       "      <th>ﬁeld</th>\n",
       "      <th>ﬁnd</th>\n",
       "      <th>ﬁndings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044386</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.10576</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.042659</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4898 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    00      000   03   04   07   09        10  100  1000  100m  ...  yes  \\\n",
       "0  0.0  0.00000  0.0  0.0  0.0  0.0  0.000000  0.0   0.0   0.0  ...  0.0   \n",
       "1  0.0  0.00000  0.0  0.0  0.0  0.0  0.000000  0.0   0.0   0.0  ...  0.0   \n",
       "2  0.0  0.00000  0.0  0.0  0.0  0.0  0.044386  0.0   0.0   0.0  ...  0.0   \n",
       "3  0.0  0.00000  0.0  0.0  0.0  0.0  0.000000  0.0   0.0   0.0  ...  0.0   \n",
       "4  0.0  0.10576  0.0  0.0  0.0  0.0  0.000000  0.0   0.0   0.0  ...  0.0   \n",
       "\n",
       "       york  yorkers  youtube  zendesk  zoomrx   zr  ﬁeld  ﬁnd  ﬁndings  \n",
       "0  0.000000      0.0      0.0      0.0     0.0  0.0   0.0  0.0      0.0  \n",
       "1  0.000000      0.0      0.0      0.0     0.0  0.0   0.0  0.0      0.0  \n",
       "2  0.000000      0.0      0.0      0.0     0.0  0.0   0.0  0.0      0.0  \n",
       "3  0.000000      0.0      0.0      0.0     0.0  0.0   0.0  0.0      0.0  \n",
       "4  0.042659      0.0      0.0      0.0     0.0  0.0   0.0  0.0      0.0  \n",
       "\n",
       "[5 rows x 4898 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#5. TFIDF\n",
    "\n",
    "# Instantiate vectorizer object\n",
    "tfidf = TfidfVectorizer(stop_words='english', max_features=50000)\n",
    "tfidf.fit(data)\n",
    "# Create a vocabulary and get word counts per document\n",
    "sparse = tfidf.fit_transform(data)\n",
    "#dtm = tfidf.transform(new_data)\n",
    "\n",
    "# Print word counts\n",
    "\n",
    "# Get feature names to use as dataframe column headers\n",
    "\n",
    "# View Feature Matrix as DataFrame\n",
    "docs = pd.DataFrame(sparse.todense(), columns = tfidf.get_feature_names())\n",
    "docs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6. NearestNeighbor Model\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "nn = NearestNeighbors(n_neighbors=5, algorithm='ball_tree')\n",
    "\n",
    "# Fit on TF-IDF Vectors\n",
    "nn.fit(docs)\n",
    "#nn.fit(dtm.todense())\n",
    "nn.kneighbors([docs.iloc[0]])\n",
    "\n",
    "ideal_job_posting_sample = [ \"\"\"Ability to translate business needs into data science products.Backed by Sequoia Capital, Madrone Partners and Jackson Square Ventures, Strava is expanding in order to exceed the needs of our growing community of global athletes. By joining our team, you will help push Strava forward in fresh, innovative ways. You will engage in interesting and challenging work that will improve the lives of our athletes every day. And in the same way that Strava is deeply committed to unlocking the potential of our athletes, we are dedicated to providing a world-class workplace where our employees can grow and thrive. Join us! Strava is an equal opportunity employer.  In keeping with the values of Strava, we make all employment decisions including hiring, evaluation, termination, promotional and training opportunities, without regard to race, religion, color, sex, age, national origin, ancestry, sexual orientation, physical handicap, mental disability, medical condition, disability, pregnancy or pregnancy-related condition, marital status, height and or weight.Apply machine learning and other relevant techniques to business problems.ou will work on a variety of projects across product teams, including but not limited to recommendation engines, geographic information systems (GIS), and anomaly detection.\"\"\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1.29889119, 1.29889119, 1.30158619, 1.30776593, 1.31633876]]),\n",
       " array([[ 41,  68, 100, 121,  39]], dtype=int64))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new = tfidf.transform(ideal_job_posting_sample)\n",
    "\n",
    "nn.kneighbors(new.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Who You Are:\\nGetty Images is looking for individuals that enjoy leveraging new and traditional Machine Learning methods to help turn large-scale business data into actionable insights.\\nThe mission of the Data Science team at Getty Images Inc. is to leverage internal and third-party data to inform other groups on how to interact with its customer base. We achieve this goal by 1) building automated solutions that apply best-in-class Machine Learning and Engineering practices and 2) continuous interactions with stakeholders to identify critical needs that deliver results relevant to the business.\\nAs a Data Scientist - ML/AI at Getty Images, you will have end-to-end autonomy and ownership of your projects, and will work closely with other business units to build scalable and robust Machine Learning pipelines that will aim to improve workflows and improve business outcomes.\\n\\nYour Next Challenge:\\nYou will join a growing team of highly-collaborative and curious Data Scientists and Data Engineers. As a member of the team, you will have the chance to interact with key business stakeholders and leadership to define the biggest area of opportunities and accelerate the delivery of a robust portfolio of Data Science models.\\nYour primary goal will be to help extract insights and unlock value from customer data by transparently injecting Machine Learning methods to assist the business, and enabling marketing and sales professionals to define campaigns and actions based on your work. You enjoy writing rigorous code and will interact with the entirety of Getty Images technology stack to build and maintain a production-level data ecosystem that tackles challenging large-scale data problems.\\nWe value learning and development, and you will be given every opportunity to work on projects that excite you. You will have the opportunity to sit at the intersection of Engineering, Marketing, Product and Leadership to inform, influence, support, and execute on key decisions.\\n\\nWhat You’ll Need:\\nA Ph.D. or MS in Computer Science, Statistics, Economics/Econometrics, Sociology, Natural Sciences or any other equivalent quantitative project is preferred. If you are self-taught and believe you are a good fit for this role, or have significant work experience, we would love to hear from you as well.\\nProven experience of having worked hands-on as a Data Scientist, preferably in a product or customer-focused organization.\\nProficiency in Machine Learning, statistical modeling and/or data mining, and a good understanding of the real-world advantages and drawbacks of various Machine Learning techniques.\\nStrong working knowledge in Python (preferred) or R, along with experience working within the Hadoop ecosystem and standard tools such as Git, bash and SQL. Knowledge of Spark and AB testing methodology is also a big plus.\\nExcellent communication skills (both written and orally), and a proven ability to comfortably produce written reports and present findings to stakeholders.\\nAbility to independently execute on a project, from ideation to delivery to stakeholders, and can pro-actively interact with other engineers at Getty Images to access necessary resources or data.\\n\\n#LI-MM1\\n\\nWho We Are:\\n\\nGetty Images is one of the most trusted and esteemed sources of visual content in the world, with over 300 million assets including photos, videos, and music, available through its industry-leading sites www.gettyimages.com and www.istock.com. The Getty Images website serves creative, business and media customers in nearly every country in the world and is the first-place people turn to discover, purchase and share powerful visual content from the world’s best photographers and videographers. Getty Images works with over 250,000 contributors and hundreds of image partners to provide comprehensive coverage of more than 160,000 news, sport and entertainment events each year, impactful creative imagery to communicate any commercial concept and the world’s deepest digital archive of historic photography.\\nGetty Images is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances. Getty Images believes that diversity is critical to our success in moving the world with images and is committed to creating an inclusive, mutually respectful environment which celebrates diversity. We seek to hire on the basis of merit, competence, performance, and business needs.'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[41]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The New York Times is seeking inventive and motivated data engineers at all levels of experience to join the Data Engineering group. In this role, you will build critical data infrastructure that surfaces data and insights across the company.\\nAbout Us\\nOur Data Engineering teams are at the intersection of business analytics, data warehousing, and software engineering. As Maxime Beauchemin wrote in “The Rise of Data Engineering”, ETL and data modeling have evolved, and the changes are about distributed systems, stream processing, and computation at scale. They’re about working with data using the same practices that guide software engineering at large. A strong data foundation is essential for The New York Times and we’re responsible for it. We use our data infrastructure to power analytics and data products and to deliver relevant experiences to our customers in real-time. We enable our company to validate strategic decisions, make smarter choices, and react to the fast changing world. We are part of a New York based technology organization with a remote-friendly workplace that includes engineers around the world. We value transparency and openness, learning, community, and continuous improvement. Check out the Times Open blog, which is written by engineers and other technical team members, and follow @nytdevs on Twitter to see what we’re up to.\\nAbout the Job\\nWe focus on the software engineering related to data replication, storage, centralized computation, and data API’s. We provide customers and partners with data tools, shared frameworks, and data services. These are the foundational core of our group which enables ourselves and others to work with data from a common underpinning. Our tools and services enable our group to scale and avoid blocking others. We reduce data redundancy by creating systems and datasets that serve as sources of record. We enable discovery and governance of our data. We support key business goals like growing our digital subscriber base, understanding how our customers use our products, and retaining our print subscribers.\\nAs a data engineer, you will:\\nRun and support a production enterprise data platform\\nDesign and develop data models\\nWork with languages like Java, Python, Go, Bash, and SQL\\nBuild batch and streaming data pipelines with tools such as Spark, Airflow, and cloud-based data services like Google’s BigQuery, Dataproc, and Pub/Sub\\nDevelop processes for automating, testing, and deploying your work\\nAbout You\\nTo thrive in this role, you are excited about data and motivated to learn new technologies. You are comfortable collaborating with engineers from other teams, product owners, business teams, and data analysts and data scientists. You are own and shape your technical domain area and move the related business goals forward. You are eager to resolve upstream data issues at the source instead of applying workarounds. You analyze and test changes to our data architectures and processes, and determine what the possible downstream effects and potential impacts to data consumers will be.\\nBenefits and Perks:\\nMake an impact by supporting our original, independent and deeply reported journalism.\\nWe provide competitive health, dental, vision and life insurance for employees and their families\\nWe support responsible retirement planning with a generous 401(k) company match.\\nWe offer a generous parental-leave policy, which we recently expanded in response to employee feedback. Birth mothers receive 16 weeks fully paid; non gestational parents receive 10 weeks, also fully paid.\\nWe are committed to career development, supported by a formal mentoring program and $8,000 annual tuition reimbursement.\\nWe have frequent panel discussions and talks by a wide variety of news makers and industry leaders.\\nJoin a community committed to the richness of diversity, experiences and talents in the world we cover, supported by a variety of employee resource groups.\\n#LI-AM1\\nThe New York Times is committed to a diverse and inclusive workforce, one that reflects the varied global community we serve. Our journalism and the products we build in the service of that journalism greatly benefit from a range of perspectives, which can only come from diversity of all types, across our ranks, at all levels of the organization. Achieving true diversity and inclusion is the right thing to do. It is also the smart thing for our business. So we strongly encourage women, veterans, people with disabilities, people of color and gender nonconforming candidates to apply.\\nThe New York Times Company is an Equal Opportunity Employer and does not discriminate on the basis of an individual's sex, age, race, color, creed, national origin, alienage, religion, marital status, pregnancy, sexual orientation or affectional preference, gender identity and expression, disability, genetic trait or predisposition, carrier status, citizenship, veteran or military status and other personal characteristics protected by law. All applications will receive consideration for employment without regard to legally protected characteristics.\""
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The New York Times is a technology company committed to producing the world’s most reliable and highest quality journalism. Our ability to do so relies on a talented team of expert technologists who help NYT learn from a tremendous abundance of data unique to this company. The Times seeks a Data Scientist to join the Data Science Group applying machine learning methods to meet this challenge, in close collaboration with working partners across the company.\\nResponsibilities:\\nReframe newsroom and business objectives as machine learning tasks that can deliver actionable insights, accurate predictions, and effective optimization.\\nImplement and execute machine learning research with reliability and reproducibility.\\nCommunicate results and impact to newsroom and business stakeholders.\\nTurn models into data products, collaborate with engineering teams, and integrate into process throughout The Times.\\nQualifications:\\nTechnical:\\nPhD, MS, or 3+ years experience in computer science, applied mathematics, or other quantitative/computational discipline.\\n2+ years experience with open source machine learning or statistical analysis tools. Familiarity with experimental design a plus.\\n2+ years coding experience, Python preferred.\\nAbility to communicate complex ideas in data science to relevant stakeholders.\\nData engineering experience, including SQL and manipulating large structured or unstructured datasets for analysis.\\nPreferred: experience with building data products, either internal or consumer-facing.\\nPreferred: Experience working with unstructured data and Natural Language Processing\\nNon-Technical:\\nCommitment to the The Times’ mission of delivering the world’s best and most reliable journalism.\\nExcellent analytical and problem-solving skills\\nStrong oral and written communication skills\\nA passion for empirical research and for answering hard questions with data.\\nProven record of solving challenging problems in academia and/or industry.\\nEagerness to collaborate with both technical and non-technical colleagues in editorial, product management, marketing, and executive leadership groups.\\nAbility to gauge the complexity of machine learning problems and a willingness to execute simple approaches for quick effective solutions as appropriate.\\nDesire to join the world’s most important journalism company at a moment in history when the importance of learning from our data is transforming every aspect of the craft and practice of journalism.\\nPlease provide GitHub or portfolio site if available.\\nBenefits and Perks:\\nSupport our original, independent and reported journalism.\\nWe provide great health, dental, vision and life insurance for employees and their families\\nWe support responsible retirement planning with a generous 401(k) company match.\\nWe offer a great parental leave.\\nWe are committed to career development and ongoing learning supported by a formal mentoring program as well as $8,000 annually for tuition reimbursement.\\nWe have frequent panel discussions and talks by newsmakers and industry leaders.\\nJoin a community committed to the richness of diversity, experiences and talents in the world we cover, supported by a variety of employee resource groups.\\n#LI-SO1\\nThe New York Times is committed to a diverse and inclusive workforce, one that reflects the varied global community we serve. Our journalism and the products we build in the service of that journalism greatly benefit from a range of perspectives, which can only come from diversity of all types, across our ranks, at all levels of the organization. Achieving true diversity and inclusion is the right thing to do. It is also the smart thing for our business. So we strongly encourage women, veterans, people with disabilities, people of color and gender nonconforming candidates to apply.\\nThe New York Times Company is an Equal Opportunity Employer and does not discriminate on the basis of an individual's sex, age, race, color, creed, national origin, alienage, religion, marital status, pregnancy, sexual orientation or affectional preference, gender identity and expression, disability, genetic trait or predisposition, carrier status, citizenship, veteran or military status and other personal characteristics protected by law. All applications will receive consideration for employment without regard to legally protected characteristics.\""
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[121]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The New York Times is a technology company committed to producing the world’s most reliable and highest quality journalism. Our ability to do so relies on a talented team of expert technologists who help NYT learn from a tremendous abundance of data unique to this company. The Times seeks a Data Scientist to join the Data Science Group applying machine learning methods to meet this challenge, in close collaboration with working partners across the company.\\nResponsibilities:\\nReframe newsroom and business objectives as machine learning tasks that can deliver actionable insights, accurate predictions, and effective optimization.\\nImplement and execute machine learning research with reliability and reproducibility.\\nCommunicate results and impact to newsroom and business stakeholders.\\nTurn models into data products, collaborate with engineering teams, and integrate into process throughout The Times.\\nQualifications:\\nTechnical:\\nPhD, MS, or 3+ years experience in computer science, applied mathematics, or other quantitative/computational discipline.\\n2+ years experience with open source machine learning or statistical analysis tools. Familiarity with experimental design a plus.\\n2+ years coding experience, Python preferred.\\nAbility to communicate complex ideas in data science to relevant stakeholders.\\nData engineering experience, including SQL and manipulating large structured or unstructured datasets for analysis.\\nPreferred: experience with building data products, either internal or consumer-facing.\\nPreferred: Experience working with unstructured data and Natural Language Processing\\nNon-Technical:\\nCommitment to the The Times’ mission of delivering the world’s best and most reliable journalism.\\nExcellent analytical and problem-solving skills\\nStrong oral and written communication skills\\nA passion for empirical research and for answering hard questions with data.\\nProven record of solving challenging problems in academia and/or industry.\\nEagerness to collaborate with both technical and non-technical colleagues in editorial, product management, marketing, and executive leadership groups.\\nAbility to gauge the complexity of machine learning problems and a willingness to execute simple approaches for quick effective solutions as appropriate.\\nDesire to join the world’s most important journalism company at a moment in history when the importance of learning from our data is transforming every aspect of the craft and practice of journalism.\\nPlease provide GitHub or portfolio site if available.\\nBenefits and Perks:\\nSupport our original, independent and reported journalism.\\nWe provide great health, dental, vision and life insurance for employees and their families\\nWe support responsible retirement planning with a generous 401(k) company match.\\nWe offer a great parental leave.\\nWe are committed to career development and ongoing learning supported by a formal mentoring program as well as $8,000 annually for tuition reimbursement.\\nWe have frequent panel discussions and talks by newsmakers and industry leaders.\\nJoin a community committed to the richness of diversity, experiences and talents in the world we cover, supported by a variety of employee resource groups.\\n#LI-SO1\\nThe New York Times is committed to a diverse and inclusive workforce, one that reflects the varied global community we serve. Our journalism and the products we build in the service of that journalism greatly benefit from a range of perspectives, which can only come from diversity of all types, across our ranks, at all levels of the organization. Achieving true diversity and inclusion is the right thing to do. It is also the smart thing for our business. So we strongly encourage women, veterans, people with disabilities, people of color and gender nonconforming candidates to apply.\\nThe New York Times Company is an Equal Opportunity Employer and does not discriminate on the basis of an individual's sex, age, race, color, creed, national origin, alienage, religion, marital status, pregnancy, sexual orientation or affectional preference, gender identity and expression, disability, genetic trait or predisposition, carrier status, citizenship, veteran or military status and other personal characteristics protected by law. All applications will receive consideration for employment without regard to legally protected characteristics.\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'As a member of RISIRISA Team, you will be joining an interdisciplinary group of scientists, mathematicians, designers, and engineers that work with commercial, public and social sector clients to help them solve their most challenging problems and get the most out of their data.\\nAs a Data Scientist, you will apply your mathematical, scientific, and/or economic training to analyze large volumes of data, model complex human-scale problems, and develop algorithms to serve various needs.\\nYou will work in collaboration with data engineers and design technologists to come up with creative solutions to challenging client problems, most often with a clear line of sight from your work to real-world impact. You will work across sectors (e.g. healthcare, cybersecurity, global development, music, etc.) and have the opportunity to regularly experiment with new tools and techniques.\\n\\n\\nRequirements\\nAdvanced Degree(s) in mathematics and/or computer science, or at least four years of relevant experience\\nPrevious work experience a big plus, especially R experience\\nExperience with a range of data science techniques including clustering, machine learning, natural language processing, and network analysis\\nEnthusiasm for learning new techniques and technologies to solve hard problems\\n\\n\\nApply to ris@risirisa.com'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[39]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(826, 1)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95, 1)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business = df.loc[((df[0]).str.contains('business')) & ((df[0]).str.contains('growing')) & ~((df[0]).str.contains('Senior'))]\n",
    "business.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>Overview\\nDo you love numbers and finding the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>Who we are\\nWe are a new and rapidly growing t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>About our team\\nWe are the Ipsos Behavioral Da...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     0\n",
       "373  Overview\\nDo you love numbers and finding the ...\n",
       "344  Who we are\\nWe are a new and rapidly growing t...\n",
       "443  About our team\\nWe are the Ipsos Behavioral Da..."
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Risk Data Scientist, NYC\\nPosition Summary:\\nM...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Description\n",
       "0  Risk Data Scientist, NYC\\nPosition Summary:\\nM..."
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rename(columns={0:'Description'}, inplace = True)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df['Preference'] = np.where(df.index.isin(business.index), 'want', 'nah')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Preference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>Job description: - Using Tensorflow Lite, impl...</td>\n",
       "      <td>nah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>Associate Consultant (Business Analysis Team)\\...</td>\n",
       "      <td>want</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>Job description: - Using Tensorflow Lite, impl...</td>\n",
       "      <td>nah</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Description Preference\n",
       "730  Job description: - Using Tensorflow Lite, impl...        nah\n",
       "285  Associate Consultant (Business Analysis Team)\\...       want\n",
       "653  Job description: - Using Tensorflow Lite, impl...        nah"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Job description: - Using Tensorflow Lite, implement data collection methods, processing, and storage (principally facial features, pupil size, ambient sound, and ambient light).\\n- Clean data for pattern/signal detection.\\n- Train data against known stimuli.\\n- Create models to predict user reactions (for example, facial features and pupil size).\\n- Brainstorm and create innovative solutions. (Understand that the variables/features thought to be indicative of outputs may very well be the extensions of bias, not the best indicators of the measured output/change.)\\nExperience: Minimum 4+ years(Must have references.)\\nExpert in:\\nPythonAzure\\nFamiliar with:\\nOpenCVTensorFlow Lite\\nKeras\\nQualities:\\nLearns quicklyAttention to detailCreative problem solverDelvers on time\\nInterview Process\\nPhone interview\\nIn-person interview\\nJob Type: Full-time\\nSalary: $80,000.00 to $150,000.00 /year\\nExperience:\\nmachine learning: 2 years (Required)\\nLocation:\\nNew York, NY (Required)\\nWork authorization:\\nUnited States (Required)'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[653]['Description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lilyx\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "...m_state=None, shuffle=True, tol=None,\n",
       "       validation_fraction=0.1, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Statements\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier#stochastic gradient descent\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from spacy.tokenizer import Tokenizer\n",
    "tokenizer = Tokenizer(nlp.vocab)\n",
    "\n",
    "# Tokenizer Pipe\n",
    "tokens = []\n",
    "\n",
    "\"\"\" Make them tokens \"\"\"\n",
    "for doc in tokenizer.pipe(df['Description'], batch_size=500):#similar to scikit learn pipeline\n",
    "    doc_tokens = [token.text for token in doc]\n",
    "    tokens.append(doc_tokens)\n",
    "#     doc_tokens = []\n",
    "#     for token in doc:\n",
    "#         if (token.is_stop == False) & (token.is_punct == False):\n",
    "#             doc_tokens.append(token.text.lower())\n",
    "            \n",
    "#    tokens.append(doc_tokens)\n",
    "    \n",
    "df['tokens'] = tokens\n",
    "\n",
    "# Create Pipeline\n",
    "\n",
    "vect = TfidfVectorizer(stop_words='english')#instantiate vectorizer\n",
    "sgdc = SGDClassifier()#instantiate classifier\n",
    "\n",
    "pipe = Pipeline([('vect', vect), ('clf', sgdc)])#put objects in pipe#the last item in pipeline, should have fit command\n",
    "pipe.fit(df['Description'], df['Preference'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['nah'], dtype='<U4')"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.predict(['As a machine learning data scientist, you will have the opportunity to leverage our robust data and machine learning infrastructure to develop models that impact millions of users across our three audiences and tackle our most challenging business problems. You will work with data scientists, engineers, and product managers to develop and iterate on models to help us grow our business.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['nah'], dtype='<U4')"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "svd = TruncatedSVD(n_components=500, #take features and reduce to how many features\n",
    "                   algorithm='randomized',#how svd is working, randomized is best bet, \n",
    "                   n_iter=10)#number of passes at estimating components\n",
    "# LSI\n",
    "\n",
    "lsi = Pipeline([('vect', vect), ('svd', svd)])\n",
    "# Pipe\n",
    "\n",
    "pipe = Pipeline([('lsi', lsi), ('clf', sgdc)])\n",
    "\n",
    "params = {\n",
    "    'lsi__vect__max_df': (10, 10, 10)#least indexing\n",
    "}\n",
    "grid_search = GridSearchCV(pipe,parameters, cv=15, n_jobs=5, verbose=1)\n",
    "# Fit\n",
    "pipe.fit(df['Description'], df['Preference'])\n",
    "# test['category'] = pipe.predict(test['description'])\n",
    "# submission = test[['id', 'category']]\n",
    "# submission.head(2)\n",
    "pipe.predict(['As a machine learning data scientist, you will have the opportunity to leverage our robust data and machine learning infrastructure to develop models that impact millions of users across our three audiences and tackle our most challenging business problems. You will work with data scientists, engineers, and product managers to develop and iterate on models to help us grow our business.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lilyx\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=None,\n",
       "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
       "       validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "def get_word_vectors(docs):\n",
    "    return [nlp(doc).vector for doc in docs]\n",
    "\n",
    "X = get_word_vectors(df['Description'])\n",
    "\n",
    "sgdc.fit(X, df['Preference'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['want'], dtype='<U4')"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgdc.predict(get_word_vectors(['As a machine learning data scientist, you will have the opportunity to leverage our robust data and machine learning infrastructure to develop models that impact millions of users across our three audiences and tackle our most challenging business problems. You will work with data scientists, engineers, and product managers to develop and iterate on models to help us grow our business.']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
